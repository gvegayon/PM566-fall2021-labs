---
title: "Lab 7"
output:
  github_document: 
    html_preview: false
  html_document: default
  word_document: default
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(repos = c(CRAN = "http://cran.rstudio.com"))
library(tidyverse)
library(tidytext)
```

```{r} 
if (knitr::is_html_output(excludes = "gfm")) {
  
}
```

## Question 1: How many sars-cov-2 papers?

```{r how-many}
# Downloading the website
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")

# Finding the counts
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/span")

xml2::xml_find_first(website, "//*[@id=\"search-results\"]/div[2]/div[1]/span")
xml2::xml_find_first(website, '//*[@id="search-results"]/div[2]/div[1]/span')

# Turning it into text
# or xml2::xml_text(counts)
counts <- as.character(counts)

# Extracting the data using regex
stringr::str_extract(counts, "[0-9,]+")
stringr::str_extract(counts, "[[:digit:],]+")
stringr::str_replace(counts, "[^[:digit:]]+([[:digit:]]+),([[:digit:]]+)[^[:digit:]]+", "\\1\\2")
```

## Q2

```{r hawaii}
library(httr)
query_ids <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi",
  query = list(
    db     = "pubmed",
    term   = "covid19 hawaii",
    retmax = 1000
    )
)

GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/",
  path  = "entrez/eutils/esearch.fcgi",
  query = list(
    db     = "pubmed",
    term   = "covid19 hawaii",
    retmax = 1000
    )
)

# Extracting the content of the response of GET
ids <- httr::content(query_ids)
ids
```

## Q3

```{r analyzing}
# Turn the result into a character vector
ids <- as.character(ids)

# Find all the ids 
ids <- stringr::str_extract_all(ids, "<Id>[[:digit:]]+</Id>")[[1]]

# Remove all the leading and trailing <Id> </Id>. Make use of "|"
# stringr::str_remove_all(ids, "</?Id>")
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
head(ids)
```

```{r retrieving-papers}
publications <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/",
  path  = "entrez/eutils/efetch.fcgi",
  query = list(
    db = "pubmed",
    id = I(paste(ids, collapse=",")),
    retmax = 1000,
    rettype = "abstract"
    )
)

# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
```



